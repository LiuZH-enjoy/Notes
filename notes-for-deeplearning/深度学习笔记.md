# 卷积神经网络

## “卷积”意义的3次改变。

- 一个系统，输入不稳定，输出稳定，用卷积求系统存量。

- 周围像素点如何产生影响（如平滑过滤

- 一个像素点如何对周边环境进行试探，采集信息（如边缘提取


## 从全连接到卷积

![19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 11_25_35](C:\Users\lzh\Videos\Captures\19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 11_25_35.png)

![19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 11_25_58](C:\Users\lzh\Videos\Captures\19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 11_25_58.png)

![19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 11_33_19](C:\Users\lzh\Videos\Captures\19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 11_33_19.png)

![19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 11_35_49](C:\Users\lzh\Videos\Captures\19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 11_35_49.png)

![19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 11_37_11](C:\Users\lzh\Videos\Captures\19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 11_37_11.png)

- Tips：

  w_{i,j,k,l}中，i,j代表输出的点在输出矩阵中的位置，k,l代表输入点在输入的图（或者矩阵）中的位置。那么这个权重矩阵应该记录输入中的每一个点对于输出中的每一个点的影响（也就是权重）。举例来说，比如输入图是4x4的，输出图是2x2的。我需要记录输入图中(1,1), (1,2), ..., (2,1), ..., (4,4)这些所有的点对输出图(1,1)的影响，同理也需要记录这些所有点对输出图中(1,2), ...., (2,2)的影响。那么这时候对于每一组点就有4个参数：输入图的横坐标、纵坐标，输出图的横坐标、纵坐标。所以要想完全记录所有的权重，需要一个4维张量。

## 卷积层

![NBA设置工具.exe - 蓝奏云 - Google Chrome 2021_8_12 15_50_31](C:\Users\lzh\Videos\Captures\NBA设置工具.exe - 蓝奏云 - Google Chrome 2021_8_12 15_50_31.png)

![19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 15_54_01](C:\Users\lzh\Videos\Captures\19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 15_54_01.png)

![19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 15_54_30](C:\Users\lzh\Videos\Captures\19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 15_54_30.png)

![19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 15_56_16](C:\Users\lzh\Videos\Captures\19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 15_56_16.png)

![19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 15_56_35](C:\Users\lzh\Videos\Captures\19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 15_56_35.png)

### 1*1卷积

![img](https://pic3.zhimg.com/80/v2-dbc59a5ad5cc41a3ec9e14b0ef51d61a_1440w.jpg?source=1940ef5c)

![image-20210818111219253](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210818111219253.png)

![image-20210818111321909](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210818111321909.png)







### 手动实现

![19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 15_59_23](C:\Users\lzh\Videos\Captures\19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 15_59_23.png)

![19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_00_44](C:\Users\lzh\Videos\Captures\19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_00_44.png)

![19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_02_06](C:\Users\lzh\Videos\Captures\19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_02_06.png)

![19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_02_19](C:\Users\lzh\Videos\Captures\19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_02_19.png)

![19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_03_10](C:\Users\lzh\Videos\Captures\19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_03_10.png)

![19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_03_29](C:\Users\lzh\Videos\Captures\19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_03_29.png)

![19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_06_08](C:\Users\lzh\Videos\Captures\19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_06_08.png)

![19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_08_24](C:\Users\lzh\Videos\Captures\19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_08_24.png)

## 卷积层里的填充

![20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_52_19](C:\Users\lzh\Videos\Captures\20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_52_19.png)

![20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_55_03](C:\Users\lzh\Videos\Captures\20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_55_03.png)

![20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_56_04](C:\Users\lzh\Videos\Captures\20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 16_56_04.png)

![20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 17_06_26](C:\Users\lzh\Videos\Captures\20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 17_06_26.png)

![20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 17_07_59](C:\Users\lzh\Videos\Captures\20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 17_07_59.png)

## 计算shape

![20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 17_11_16](C:\Users\lzh\Videos\Captures\20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 17_11_16.png)

![20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 18_08_22](C:\Users\lzh\Videos\Captures\20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 18_08_22.png)

### 代码实现

![20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 21_09_42](C:\Users\lzh\Videos\Captures\20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 21_09_42.png)

![20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 21_11_26](C:\Users\lzh\Videos\Captures\20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 21_11_26.png)

![20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 21_47_41](C:\Users\lzh\Videos\Captures\20 卷积层里的填充和步幅【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_12 21_47_41.png)

## 多个输入通道

![21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 8_56_48 (1)](C:\Users\lzh\Videos\Captures\21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 8_56_48 (1).png)

![21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 8_58_37](C:\Users\lzh\Videos\Captures\21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 8_58_37.png)

![21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 9_00_55](C:\Users\lzh\Videos\Captures\21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 9_00_55.png)

![21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 9_11_12](C:\Users\lzh\Videos\Captures\21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 9_11_12.png)

![21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 9_17_11](C:\Users\lzh\Videos\Captures\21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 9_17_11.png)

![21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 9_19_11](C:\Users\lzh\Videos\Captures\21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 9_19_11.png)

![21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 9_33_22](C:\Users\lzh\Videos\Captures\21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 9_33_22.png)

### 实现多通道卷积

![21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 9_53_05](C:\Users\lzh\Videos\Captures\21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 9_53_05.png)

![21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 9_48_29](C:\Users\lzh\Videos\Captures\21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 9_48_29.png)

![21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 9_56_28](C:\Users\lzh\Videos\Captures\21 卷积层里的多输入多输出通道【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 9_56_28.png)

# 池化层

## 理论介绍

![22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 11_20_28](C:\Users\lzh\Videos\Captures\22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 11_20_28.png)

![22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 11_24_52](C:\Users\lzh\Videos\Captures\22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 11_24_52.png)

![22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 11_26_52](C:\Users\lzh\Videos\Captures\22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 11_26_52.png)

![22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 11_28_04](C:\Users\lzh\Videos\Captures\22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 11_28_04.png)

![22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 11_30_03](C:\Users\lzh\Videos\Captures\22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 11_30_03.png)

![22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 11_31_01](C:\Users\lzh\Videos\Captures\22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_13 11_31_01.png)

## 代码实现

![22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 15_23_45](C:\Users\lzh\Videos\Captures\22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 15_23_45.png)

![22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 16_35_47](C:\Users\lzh\Videos\Captures\22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 16_35_47.png)

![22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 16_37_30](C:\Users\lzh\Videos\Captures\22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 16_37_30.png)

![22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 16_51_22](C:\Users\lzh\Videos\Captures\22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 16_51_22.png)

![22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 17_03_09](C:\Users\lzh\Videos\Captures\22 池化层【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 17_03_09.png)

# LeNet 代码实现

![23 经典卷积神经网络 LeNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 19_03_55](C:\Users\lzh\Videos\Captures\23 经典卷积神经网络 LeNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 19_03_55.png)

![23 经典卷积神经网络 LeNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 19_05_47](C:\Users\lzh\Videos\Captures\23 经典卷积神经网络 LeNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 19_05_47.png)

![23 经典卷积神经网络 LeNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 19_06_18](C:\Users\lzh\Videos\Captures\23 经典卷积神经网络 LeNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 19_06_18.png)

![23 经典卷积神经网络 LeNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 19_06_22](C:\Users\lzh\Videos\Captures\23 经典卷积神经网络 LeNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_14 19_06_22.png)

![23 经典卷积神经网络 LeNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_15 10_17_10](C:\Users\lzh\Videos\Captures\23 经典卷积神经网络 LeNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_15 10_17_10.png)

![23 经典卷积神经网络 LeNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_15 10_18_09](C:\Users\lzh\Videos\Captures\23 经典卷积神经网络 LeNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_15 10_18_09.png)

![23 经典卷积神经网络 LeNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_15 10_19_00](C:\Users\lzh\Videos\Captures\23 经典卷积神经网络 LeNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_15 10_19_00.png)

# AlexNet

![24 深度卷积神经网络 AlexNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_15 12_09_56](C:\Users\lzh\Videos\Captures\24 深度卷积神经网络 AlexNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_15 12_09_56.png)

![24 深度卷积神经网络 AlexNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_15 12_29_56](C:\Users\lzh\Videos\Captures\24 深度卷积神经网络 AlexNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_15 12_29_56.png)

![24 深度卷积神经网络 AlexNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_15 12_31_33](C:\Users\lzh\Videos\Captures\24 深度卷积神经网络 AlexNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_15 12_31_33.png)

## 代码实现

```python
net = nn.Sequential(
      nn.Conv2d(3,96,kernel_size=11,stride=4,padding=2),nn.ReLU(),
      nn.MaxPool2d(kernel_size=3,stride=2), # 
      nn.Conv2d(96,128*2,kernel_size=5,padding=2),nn.ReLU(),
      nn.MaxPool2d(kernel_size=3,stride=2),
      nn.Conv2d(128*2,192*2,kernel_size=3,padding=1),nn.ReLU(),
      nn.Conv2d(192*2,192*2,kernel_size=3,padding=1),nn.ReLU(),
      nn.Conv2d(192*2,128*2,kernel_size=3,padding=1),nn.ReLU(),
      nn.MaxPool2d(kernel_size=3,stride=2), # 6*6*256
      nn.Flatten(),
      nn.Linear(6*6*256,2048*2),nn.ReLU(),nn.Dropout(p=0.5),
      nn.Linear(2048*2,2048*2),nn.ReLU(),nn.Dropout(p=0.5),
      nn.Linear(2048*2,1000),nn.ReLU(),
    )
```

卷积层结束后，需要知道进入感知机的元素个数，可以用如下测试代码：

```python
x = torch.rand(size=(1,1,224,224),dtype=torch.float32)
for layer in net:
  x = layer(x)
  print(layer.__class__.__name__,
        f\t{x.shape})
```

```python
结果：
Conv2d 	torch.Size(【1, 96, 54, 54】)
ReLU 	torch.Size(【1, 96, 54, 54】)
MaxPool2d 	torch.Size(【1, 96, 26, 26】)
Conv2d 	torch.Size(【1, 256, 26, 26】)
ReLU 	torch.Size(【1, 256, 26, 26】)
MaxPool2d 	torch.Size(【1, 256, 12, 12】)
Conv2d 	torch.Size(【1, 384, 12, 12】)
ReLU 	torch.Size(【1, 384, 12, 12】)
Conv2d 	torch.Size(【1, 384, 12, 12】)
ReLU 	torch.Size(【1, 384, 12, 12】)
Conv2d 	torch.Size(【1, 256, 12, 12】)
ReLU 	torch.Size(【1, 256, 12, 12】)
MaxPool2d 	torch.Size(【1, 256, 5, 5】)
Flatten 	torch.Size(【1, 6400】)

可以得知输入元素为6400
```



# VGG：使用块的网络

![25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 17_19_02](C:\Users\lzh\Videos\Captures\25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 17_19_02.png)

![25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 17_27_30](C:\Users\lzh\Videos\Captures\25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 17_27_30.png)

![25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 17_30_57](C:\Users\lzh\Videos\Captures\25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 17_30_57.png)

![25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 17_42_29](C:\Users\lzh\Videos\Captures\25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 17_42_29.png)

![25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 17_47_40](C:\Users\lzh\Videos\Captures\25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 17_47_40.png)

## 代码实现

```python
import torch 
from torch import nn

def vgg_block(num_conv,in_channels,out_channels) -nn.Sequential:
  layers = []
  for _ in range(num_conv):
    layers.append(nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1))
    layers.append(nn.ReLU())
    in_channels = out_channels
  layers.append(nn.MaxPool2d(kernel_size=2,stride=2))
  return nn.Sequential(*layers)
```

```python
class vgg_net(nn.Module):
  def __init__(self,cfg:tuple,in_channels) - None:
    super(vgg_net,self).__init__()
    layers = []
    for num_conv,out_channels in cfg:
      layers.append(vgg_block(num_conv,in_channels,out_channels))
      in_channels = out_channels
    self.model = nn.Sequential(*layers,
                  nn.Flatten(),
                  nn.Linear(in_channels * 7 * 7,4096),nn.ReLU(),nn.Dropout(p=0.5),
                  nn.Linear(4096,4096),nn.ReLU(),nn.Dropout(p=0.5),
                  nn.Linear(4096,10)
                  )
  def forward(self,X:torch.Tensor):
    for layer in self.model:
      X=layer(X)
      print(layer.__class__.__name__,output shape：\t,X.shape)
    print(X)
    return nn.Softmax(1)(X)
```

![25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 18_08_00](C:\Users\lzh\Videos\Captures\25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 18_08_00.png)

![25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 18_08_11](C:\Users\lzh\Videos\Captures\25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 18_08_11.png)

![25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 18_11_14](C:\Users\lzh\Videos\Captures\25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 18_11_14.png)

![25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 18_11_25](C:\Users\lzh\Videos\Captures\25 使用块的网络 VGG【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_17 18_11_25.png)

# NiN

![Instagram - Google Chrome 2021_8_18 9_38_06](C:\Users\lzh\Videos\Captures\Instagram - Google Chrome 2021_8_18 9_38_06.png)

![Instagram - Google Chrome 2021_8_18 9_47_06](C:\Users\lzh\Videos\Captures\Instagram - Google Chrome 2021_8_18 9_47_06.png)

![26 网络中的网络 NiN【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_18 11_21_36](C:\Users\lzh\Videos\Captures\26 网络中的网络 NiN【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_18 11_21_36.png)

  ![26 网络中的网络 NiN【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_18 11_26_16](C:\Users\lzh\Videos\Captures\26 网络中的网络 NiN【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_18 11_26_16.png)

![26 网络中的网络 NiN【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_18 11_26_31](C:\Users\lzh\Videos\Captures\26 网络中的网络 NiN【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_18 11_26_31.png)

## 代码实现

![26 网络中的网络 NiN【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 14_36_14](C:\Users\lzh\Videos\Captures\26 网络中的网络 NiN【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 14_36_14.png)

![26 网络中的网络 NiN【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 14_36_43](C:\Users\lzh\Videos\Captures\26 网络中的网络 NiN【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 14_36_43.png)

![26 网络中的网络 NiN【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 14_40_04](C:\Users\lzh\Videos\Captures\26 网络中的网络 NiN【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 14_40_04.png)

![26 网络中的网络 NiN【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 14_45_22](C:\Users\lzh\Videos\Captures\26 网络中的网络 NiN【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 14_45_22.png)

# GoogleNet

![27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 16_28_25](C:\Users\lzh\Videos\Captures\27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 16_28_25.png)



![27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 16_29_09](C:\Users\lzh\Videos\Captures\27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 16_29_09.png)

![27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_14_33](C:\Users\lzh\Videos\Captures\27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_14_33.png)

![27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_16_27](C:\Users\lzh\Videos\Captures\27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_16_27.png)

![27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_29_13](C:\Users\lzh\Videos\Captures\27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_29_13.png)

![27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_32_45](C:\Users\lzh\Videos\Captures\27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_32_45.png)

![27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_34_27](C:\Users\lzh\Videos\Captures\27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_34_27.png)

![27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_35_51](C:\Users\lzh\Videos\Captures\27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_35_51.png)

![27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_37_14](C:\Users\lzh\Videos\Captures\27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_37_14.png)

![27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_37_20](C:\Users\lzh\Videos\Captures\27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_37_20.png)

![27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_37_41](C:\Users\lzh\Videos\Captures\27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_37_41.png)

![27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_38_58](C:\Users\lzh\Videos\Captures\27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_38_58.png)

## 代码实现

![27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_53_13](C:\Users\lzh\Videos\Captures\27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 17_53_13.png)

![27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 18_00_01](C:\Users\lzh\Videos\Captures\27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 18_00_01.png)

![27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 18_03_45](C:\Users\lzh\Videos\Captures\27 含并行连结的网络 GoogLeNet _ Inception V3【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_30 18_03_45.png)

# 批量归一化

![28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 11_28_11](C:\Users\lzh\Videos\Captures\28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 11_28_11.png)

![28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 11_30_41](C:\Users\lzh\Videos\Captures\28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 11_30_41.png)

![28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 11_33_53](C:\Users\lzh\Videos\Captures\28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 11_33_53.png)

![28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 11_36_53](C:\Users\lzh\Videos\Captures\28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 11_36_53.png)

![28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 11_43_48](C:\Users\lzh\Videos\Captures\28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 11_43_48.png)

## 代码实现

![28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 11_52_23](C:\Users\lzh\Videos\Captures\28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 11_52_23.png)

![28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 12_04_02](C:\Users\lzh\Videos\Captures\28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 12_04_02.png)

![28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 12_09_50](C:\Users\lzh\Videos\Captures\28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 12_09_50.png)

![28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 12_24_02](C:\Users\lzh\Videos\Captures\28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 12_24_02.png)

![28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 12_24_32](C:\Users\lzh\Videos\Captures\28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 12_24_32.png)

![28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 12_26_13](C:\Users\lzh\Videos\Captures\28 批量归一化【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_31 12_26_13.png)



# ResNet

![29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_26_58](C:\Users\lzh\Videos\Captures\29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_26_58.png)

![29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_28_11](C:\Users\lzh\Videos\Captures\29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_28_11.png)

![29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_30_15](C:\Users\lzh\Videos\Captures\29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_30_15.png)

![29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_31_02](C:\Users\lzh\Videos\Captures\29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_31_02.png)

![29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_31_51](C:\Users\lzh\Videos\Captures\29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_31_51.png)

![29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_35_18](C:\Users\lzh\Videos\Captures\29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_35_18.png)

## 代码实现

![29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_40_24](C:\Users\lzh\Videos\Captures\29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_40_24.png)

![29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_47_53](C:\Users\lzh\Videos\Captures\29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_47_53.png)

![29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_48_58](C:\Users\lzh\Videos\Captures\29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 9_48_58.png)

![29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 10_02_43](C:\Users\lzh\Videos\Captures\29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 10_02_43.png)

![29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 10_05_05](C:\Users\lzh\Videos\Captures\29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 10_05_05.png)

![29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 10_06_13](C:\Users\lzh\Videos\Captures\29 残差网络 ResNet【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 10_06_13.png)

## Why ResNet可以work？

![29.2 ResNet为什么能训练出1000层的模型【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 10_53_49](C:\Users\lzh\Videos\Captures\29.2 ResNet为什么能训练出1000层的模型【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_9_1 10_53_49.png)

- 1 加深模型可以退化为浅层模型

- 2 梯度高速通道

  接近数据输入的那些参数比较难更新，当上端靠近模型输出的那些层已经训练得比较好时（拟合效果较好的层），传下来的梯度会比较小，使得参数更新没那么快。这时候使用ResNet可以解除对上层梯度传递的依赖，直接算接近所更新参数的层对参数的梯度（这就是梯度高速公路），可以得到较大的梯度，使得参数及时更新。









# 感知机

- *问题：为什么会有感知机的提出？多对一，在数学上存在函数，在数据结构上存在树结构，为什么不直接利用这两个东西，而是创造出感知机的概念？到底是新瓶装旧酒，还是真的是一个新的东西呢？*

感知机的缺陷：单个感知机无法表示异或运算（就是存在线性不可分的情况

解决方法：多个感知机组合或者根据盖尔定理：通过升维来对在低微线性不可分的样本进行线性分割。（核方法）

感知机：就是一个分类模板，包括线性函数+激活函数。功能有限，只能解决线性二分的问题，如果是异或或者是非线性问题就无法解决了。

### 训练感知机

![10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 14_56_23](C:\Users\lzh\Videos\Captures\10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 14_56_23.png)

### 收敛定理

![10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 15_06_58](C:\Users\lzh\Videos\Captures\10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 15_06_58.png)



### 缺陷

![10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 15_09_34](C:\Users\lzh\Videos\Captures\10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 15_09_34.png)



### 总结

![10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 15_10_29](C:\Users\lzh\Videos\Captures\10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 15_10_29.png)

### 学习XOR

![10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 16_06_23](C:\Users\lzh\Videos\Captures\10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 16_06_23.png)

### 单分类

![10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 16_07_09](C:\Users\lzh\Videos\Captures\10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 16_07_09.png)

### 激活函数

![10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 16_07_22](C:\Users\lzh\Videos\Captures\10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 16_07_22.png)

![10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 16_07_26](C:\Users\lzh\Videos\Captures\10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 16_07_26.png)

![10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 16_07_30](C:\Users\lzh\Videos\Captures\10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 16_07_30.png)

### 多分类

![10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 16_07_50](C:\Users\lzh\Videos\Captures\10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 16_07_50.png)

![10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 16_08_18](C:\Users\lzh\Videos\Captures\10 多层感知机 + 代码实现 - 动手学深度学习v2_哔哩哔哩_bilibili - Google Chrome 2021_7_21 16_08_18.png)



# 损失函数的由来

- 极大似然的角度理解损失函数

神经网络就是不断调整参数使得其概率模型与人脑的模型逼近，神经网络里的参数是W、b，模型是由这两个参数决定的。抛硬币与给图片打标签都是现实真实发生的事件，则使得这些事件发生概率最大的参数W、b则为最逼近现实模型的参数！！！
$$
P(x_1, x_2, x_3, \dots, x_n|W, b)=\prod_{i=1}^{n} P(x_i|W,b)=\prod_{i=1}^{n}P(x_i|y_i)=\prod_{i=1}^{n}y_i^{x_i}(1-y_i)^{1-x_i}
$$
yi代表该图片是猫的概率，xi为标签值（1代表是猫，0代表不是）
$$
log(\prod_{i=1}^{n}y_i^{x_i}(1-y_i)^{1-x_i})=\sum_{i=1}^{n}log(y_i^{x_i}(1-y_i)^{1-x_i})=\sum_{i=1}^{n}(x_i*logy_i+(1-x_i)*log(1-y_i))
$$
损失函数一般求最小，因此有：
$$
min-(\sum_{i=1}^{n}(x_i*logy_i+(1-x_i)*log(1-y_i)))
$$
显然这里就是人们常说的交叉熵损失，但这个明明是由极大似然求出来的，它们之间有什么关系吗？

# 交叉熵（2021.7.20）

神经网络训练的关键就是：如何定量衡量两个模型间的差距？前面也介绍了两种：1.最小二乘  2.极大似然估计

第三种方法就是交叉熵，先把模型转换成熵这么一个数值，再用熵去比较不同模型之间的差异。

### 定义信息量：

$$
f(x):=信息量
$$

$$
f(阿根廷夺冠)=f(阿根廷进决赛)+f(阿根廷赢了决赛)
$$

$$
f(\frac{1}{8})=f(\frac{1}{4})+f(\frac{1}{2})
$$

而同时我们也注意到：
$$
P(阿根廷夺冠)=P(阿根廷进决赛)*P(阿根廷赢了决赛)
$$
所以熵的定义必须满足条件：
$$
f(x):=信息量
$$

$$
f(x_1+x_2)=f(x_1)*f(x_2)
$$

故为了方法自洽，可推断熵的定义为：
$$
f(x):=-log_{2}(x)
$$

### 系统熵的定义：

$$
H(P):=E(P_f)=\sum_{i=1}^{m}p_i*f(p_i)=\sum_{i=1}^{m}p_i(-log_2p_i)=-\sum_{i=1}^{m}p_i*log_2p_i
$$

如何比较两个系统熵的区别呢？（比较两个模型）

### KL散度

$$
D_{KL}(P||Q):=\sum_{i=1}^{m}p_i(f_Q(q_i)-f_P(p_i))=\sum_{i=1}^{m}p_i((-log_2q_i)-(-log_2p_i))=\sum_{i=1}^{m}p_i(-log_2q_i)-\sum_{i=1}^{m}p_i(-log_2p_i)
$$

这里P在前，就是以P为基准去考虑Q和P相差有多少。

对于同一个事件i，计算在Q系统与P系统的差异，再乘以相应权重（相当于求期望）。

直观理解就是如果P想要达到和Q同样的分布的话，他们中间还差了多少信息量。

从KL散度最后化简的结果可以看到，后面那个式子就是P的熵，而前面的式子为P的交叉熵：H(P,Q)

由吉布斯不等式可知，KL散度大于等于0，因此，P的熵是定值，我们可以利用交叉熵H(P,Q)来作为损失函数，衡量Q系统与P系统间的差异。

### 将交叉熵应用到神经网络中

$$
H(P,Q)=\sum_{i=1}^{m}p_i*(-log_2q_i)=\sum_{i=1}^{n}x_i*(-log_2q_i)=-\sum_{i=1}^{n}(x_i*log_2y_i+(1-x_i)log_2(1-y_i))
$$

*这里要注意，xi只有0，1两个值，也就是两种事件，所以这里不能直接用yi来对应，yi表示的是这图片经过神经网络判断后，它有多像猫，对应的是xi为1的情况，没有对应到xi为0的情况，所以我们这里需要再次展开，把相同事件一一对应起来*

到这一步我们就可以知道，想要知道哪两个概率模型最为相近，就是要求交叉熵最小的那个。

### 总结

极大似然估计与交叉熵推导出的形式上虽然一样，但过程与思路完全不同。log与前面的负号在极大似然估计中是人为习惯加上的，而在交叉熵中是熵这个系统的严格定义的。

**学习的时候，中心在学习，还是在知识？**

# 从回归到多分类（2021.7.20）

### 回归

- 单连续数值输出
- 自然区间R
- 跟真实值的区别作为损失

### 分类

- 通常多个数值输出
- 输出i是预测为第i类的置信度

### softmax和交叉熵损失

- 交叉熵常用来衡量两个概率的区别
  $$
  H(p,q)=\sum_{i}-p_ilog(q_i)
  $$

- 将它作为损失

  

$$
l(y,\hat{y})=-\sum_{i}y_ilog\hat{y_i}=-log\hat{y_y}
$$

- 其梯度是真是概率和预测概率的区别
  $$
  \partial_{o_i}l(y,\hat{y})=softmax(o_i)-y_i
  $$
  

### 总结

- softmax是一个多类分类模型
- 使用softmax操作子得到每个类的预测置信度
- 使用交叉熵来衡量预测和标号的区别

# 模型选择

### 训练误差和泛化误差

![11 模型选择 + 过拟合和欠拟合【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_22 16_34_41 (1)](C:\Users\lzh\Videos\Captures\11 模型选择 + 过拟合和欠拟合【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_22 16_34_41 (1).png)

### 验证数据集和测试数据集

![11 模型选择 + 过拟合和欠拟合【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_22 16_36_15](C:\Users\lzh\Videos\Captures\11 模型选择 + 过拟合和欠拟合【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_22 16_36_15.png)

### K-则交叉验证

![11 模型选择 + 过拟合和欠拟合【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_22 16_37_08](C:\Users\lzh\Videos\Captures\11 模型选择 + 过拟合和欠拟合【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_22 16_37_08.png)

### 模型容量的影响

![11 模型选择 + 过拟合和欠拟合【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_22 21_14_49](C:\Users\lzh\Videos\Captures\11 模型选择 + 过拟合和欠拟合【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_22 21_14_49.png)

### 估计模型容量

![11 模型选择 + 过拟合和欠拟合【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_22 21_18_26](C:\Users\lzh\Videos\Captures\11 模型选择 + 过拟合和欠拟合【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_22 21_18_26.png)

### VC维

![11 模型选择 + 过拟合和欠拟合【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_22 21_26_28](C:\Users\lzh\Videos\Captures\11 模型选择 + 过拟合和欠拟合【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_22 21_26_28.png)

### 线性分类器的VC维

![11 模型选择 + 过拟合和欠拟合【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_22 21_27_25](C:\Users\lzh\Videos\Captures\11 模型选择 + 过拟合和欠拟合【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_22 21_27_25.png)

# 权重衰退

### 模型容量的硬性控制

![12 权重衰退【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_30 11_30_34](C:\Users\lzh\Videos\Captures\12 权重衰退【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_30 11_30_34.png)

### 柔性控制

![12 权重衰退【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_30 11_33_54](C:\Users\lzh\Videos\Captures\12 权重衰退【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_30 11_33_54.png)

### 参数更新中的权重衰退

![12 权重衰退【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_30 11_44_14](C:\Users\lzh\Videos\Captures\12 权重衰退【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_7_30 11_44_14.png)

# LSTM

### Forget Gate

![LSTM_ForgetGate](C:\Users\lzh\Videos\dl\LSTM_ForgetGate.png)

### Input Gate

![LSTM_InputGate](C:\Users\lzh\Videos\dl\LSTM_InputGate.png)

### New Value

![LSTM_NewValue](C:\Users\lzh\Videos\dl\LSTM_NewValue.png)

### Update C_t

![LSTM_UpdateC_t](C:\Users\lzh\Videos\dl\LSTM_UpdateC_t.png)

### Output Gate

![LSTM_OutputGate](C:\Users\lzh\Videos\dl\LSTM_OutputGate.png)

### Update State(h_t)

![LSTM_UpdateH_t](C:\Users\lzh\Videos\dl\LSTM_UpdateH_t.png)

# Attention

## Seq2Seq_Shortcoming

![Seq2Seq_shortcoming](C:\Users\lzh\Videos\dl\Seq2Seq_shortcoming.png)

![Seq2Seq_shortcoming_2](C:\Users\lzh\Videos\dl\Seq2Seq_shortcoming_2.png)

![Seq2Seq_shortcoming_3](C:\Users\lzh\Videos\dl\Seq2Seq_shortcoming_3.png)

这时候seq2seq模型，Encoder和Decoder都是用的RNN模型，有遗忘的缺点。下面用Attention去改善RNN

## SimpleRNN+Attention

![SimpleRNN+Attention](C:\Users\lzh\Videos\dl\SimpleRNN+Attention.png)

![Attention-CalculateWeight](C:\Users\lzh\Videos\dl\Attention-CalculateWeight.png)

![Attention-ContextVector](C:\Users\lzh\Videos\dl\Attention-ContextVector.png)

![Attention-UpdateS_t](C:\Users\lzh\Videos\dl\Attention-UpdateS_t.png)

![Attention-TimeComplexity](C:\Users\lzh\Videos\dl\Attention-TimeComplexity.png)

![Attention-Summary](C:\Users\lzh\Videos\dl\Attention-Summary.png)

## SimpleRNN + Self-Attention  

就是利用self-attention去更新状态参数ht

![SimpleRNN+Self-Attention-1](C:\Users\lzh\Videos\dl\SimpleRNN+Self-Attention-1.png)

![SimpleRNN+Self-Attention-2](C:\Users\lzh\Videos\dl\SimpleRNN+Self-Attention-2.png)

![SimpleRNN+Self-Attention-3](C:\Users\lzh\Videos\dl\SimpleRNN+Self-Attention-3.png)

![SimpleRNN+Self-Attention-4](C:\Users\lzh\Videos\dl\SimpleRNN+Self-Attention-4.png)

![SimpleRNN+Self-Attention-5](C:\Users\lzh\Videos\dl\SimpleRNN+Self-Attention-5.png)

![SimpleRNN+Self-Attention-6](C:\Users\lzh\Videos\dl\SimpleRNN+Self-Attention-6.png)

![SimpleRNN+Self-Attention-7](C:\Users\lzh\Videos\dl\SimpleRNN+Self-Attention-7.png)

## Attention for Seq2Seq 

![SimpleRNN+Self-Attention-8](C:\Users\lzh\Videos\dl\SimpleRNN+Self-Attention-8.png)

## Attention without RNN  

![Attention_layer-1](C:\Users\lzh\Videos\dl\Attention_layer-1.png)

![Attention_layer-2](C:\Users\lzh\Videos\dl\Attention_layer-2.png)

![Attention_layer-3](C:\Users\lzh\Videos\dl\Attention_layer-3.png)

![Attention_layer-4](C:\Users\lzh\Videos\dl\Attention_layer-4.png)

![Attention_layer-5](C:\Users\lzh\Videos\dl\Attention_layer-5.png)

![Attention_layer-6](C:\Users\lzh\Videos\dl\Attention_layer-6.png)

![Attention_layer-7](C:\Users\lzh\Videos\dl\Attention_layer-7.png)

## Self-Attention without RNN

![Attention_layer-8](C:\Users\lzh\Videos\dl\Attention_layer-8.png)

![Attention_layer-9](C:\Users\lzh\Videos\dl\Attention_layer-9.png)

![Attention_layer-10](C:\Users\lzh\Videos\dl\Attention_layer-10.png)

![Attention_layer-11](C:\Users\lzh\Videos\dl\Attention_layer-11.png)

![Attention_layer-12](C:\Users\lzh\Videos\dl\Attention_layer-12.png)







# Dropout

![13 丢弃法【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_2 16_38_19](C:\Users\lzh\Videos\Captures\13 丢弃法【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_2 16_38_19.png)

![13 丢弃法【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_2 16_38_35](C:\Users\lzh\Videos\Captures\13 丢弃法【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_2 16_38_35.png)

![13 丢弃法【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_2 16_40_16](C:\Users\lzh\Videos\Captures\13 丢弃法【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_2 16_40_16.png)

![13 丢弃法【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_3 8_25_42](C:\Users\lzh\Videos\Captures\13 丢弃法【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_3 8_25_42.png)

# 数值稳定性

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_14_30](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_14_30.png)

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_14_50](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_14_50.png)

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_15_31](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_15_31.png)

### 梯度爆炸

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_17_16](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_17_16.png)

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_19_06](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_19_06.png)

### 梯度消失

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_37_35](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_37_35.png)

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_38_17](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_38_17.png)

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_38_46](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_38_46.png)

### 总结

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_42_53](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_6 17_42_53.png)

### 如何解决

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 9_06_43 (1)](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 9_06_43 (1).png)

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 9_09_07](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 9_09_07.png)

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 9_12_11](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 9_12_11.png)

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 10_10_40](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 10_10_40.png)

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 10_24_45](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 10_24_45.png)

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 11_42_55](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 11_42_55.png)

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 10_31_34](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 10_31_34.png)

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 10_34_13](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 10_34_13.png)

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 10_43_10](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 10_43_10.png)

**因此要求激活函数在所定范围内需要近似满足：f(x)=x**

![14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 10_43_23](C:\Users\lzh\Videos\Captures\14 数值稳定性 + 模型初始化和激活函数【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_7 10_43_23.png)

# Pytorch神经网络基础

### 模型构造

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_22_14 (1)](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_22_14 (1).png)

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_23_14](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_23_14.png)

- 自定义Sequential模块

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_23_25](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_23_25.png)

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_26_21](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_26_21.png)

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_26_52](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_26_52.png)

### 参数管理

#### 参数访问

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_27_58](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_27_58.png)

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_28_31](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_28_31.png)

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_29_39](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_29_39.png)

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_30_39](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_30_39.png)

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_31_08](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_31_08.png)

#### 参数初始化

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_31_25](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_31_25.png)

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_32_55](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_32_55.png)

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_33_15](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_33_15.png)

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_34_16](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_34_16.png)

### 自定义层

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_36_34](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_36_34.png)

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_37_00](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_37_00.png)

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_37_33](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_37_33.png)

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_43_30](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_43_30.png)

### 读写文件

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_45_16](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_45_16.png)

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_48_39](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_48_39.png)

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_48_58](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_48_58.png)

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_49_17](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_49_17.png)

![16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_49_33](C:\Users\lzh\Videos\Captures\16 PyTorch 神经网络基础【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_10 16_49_33.png)

### argparse

argparse是一个命令行解析器，使用时需要先创建一个ArgumentParser对象，然后通过调用add_argument()方法添加程序参数信息。这些信息在parser_args()调用时被存储和使用。



### python装饰器

对于一个最简单的二层装饰器，其实就是外层函数传入被装饰的函数的函数名，内层函数要么调用这个被装饰的函数，要么返回这个被装饰的函数的函数名，外层函数返回内层函数的函数名。装饰的过程在内层函数中完成。



# 使用GPU

![17 使用和购买 GPU【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_11 16_57_00](C:\Users\lzh\Videos\Captures\17 使用和购买 GPU【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_11 16_57_00.png)

![17 使用和购买 GPU【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_11 16_59_43](C:\Users\lzh\Videos\Captures\17 使用和购买 GPU【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_11 16_59_43.png)

![17 使用和购买 GPU【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_11 17_00_25](C:\Users\lzh\Videos\Captures\17 使用和购买 GPU【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_11 17_00_25.png)

![17 使用和购买 GPU【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_11 17_04_37](C:\Users\lzh\Videos\Captures\17 使用和购买 GPU【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_11 17_04_37.png)

![17 使用和购买 GPU【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_11 17_05_13](C:\Users\lzh\Videos\Captures\17 使用和购买 GPU【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_11 17_05_13.png)

![17 使用和购买 GPU【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_11 17_06_47](C:\Users\lzh\Videos\Captures\17 使用和购买 GPU【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_11 17_06_47.png)

![17 使用和购买 GPU【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_11 17_07_08](C:\Users\lzh\Videos\Captures\17 使用和购买 GPU【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_11 17_07_08.png)

![17 使用和购买 GPU【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_11 17_08_32](C:\Users\lzh\Videos\Captures\17 使用和购买 GPU【动手学深度学习v2】_哔哩哔哩_bilibili - Google Chrome 2021_8_11 17_08_32.png)

# Resnet解决了什么问题

作者：大雄007
链接：https://www.zhihu.com/question/64494691/answer/1825690955
来源：知乎

相较于VGG的19层和GoogLeNet的22层，ResNet可以提供18、34、50、101、152甚至更多层的网络，同时获得更好的精度。但是为什么要使用更深层次的网络呢？同时，如果只是网络层数的堆叠，那么为什么前人没有获得ResNet一样的成功呢？

## 1、为什么要使用更深层次的网络？

从理论上来讲，加深深度学习网络可以提升性能。深度网络以端到端的多层方式集成了低/中/高层特征和分类器，且特征的层次可通过加深网络层次的方式来丰富。举一个例子，当深度学习网络只有一层时，要学习的特征会非常复杂，但如果有多层，就可以分层进行学习。如图1中，网络的第一层学习到了边缘和颜色，第二层学习到了纹理，第三层学习到了局部的形状，而第五层已逐渐学习到全局特征。网络的加深，理论上可以提供更好的表达能力，使每一层学习到更细化的特征。

![img](https://pic3.zhimg.com/50/v2-c3d586cd076d95e72de87038b9c6a23e_720w.jpg?source=1940ef5c)



## 2、梯度消失 or 爆炸

但网络加深真的只有堆叠层数这么简单么？当然不是！首先，最显著的问题就是梯度消失或梯度爆炸。我们都知道神经网络的参数更新依靠梯度反向传播（Back Propagation），那么为什么会出现梯度的消失和爆炸呢？举一个例子解释。如图2所示情况，假设每层只有一个神经元，且激活函数使用Sigmoid函数，则有

![[公式]](https://www.zhihu.com/equation?tex=y_i%3D+%CF%83%28z_i+%29%3D+%CF%83%28w_i+x_i%2B+b_i+%29%2C%CF%83%E4%B8%BAsigmoid%E5%87%BD%E6%95%B0) 

![img](https://pic2.zhimg.com/50/v2-ba179df8ac9510ccf45b27e69335da87_720w.jpg?source=1940ef5c)![img](https://pic2.zhimg.com/80/v2-ba179df8ac9510ccf45b27e69335da87_1440w.jpg?source=1940ef5c)



根据链式求导和反向传播，我们可以得到：

![img](https://pic1.zhimg.com/50/v2-aaa4e73f3203d09617181c6379ae161e_720w.jpg?source=1940ef5c)![img](https://pic1.zhimg.com/80/v2-aaa4e73f3203d09617181c6379ae161e_1440w.jpg?source=1940ef5c)

Sigmoid函数的导数 ![[公式]](https://www.zhihu.com/equation?tex=%CF%83%27+%28x%29) 如图所示：



![img](https://pic2.zhimg.com/50/v2-180e3525899c22b81033fc1a5462303d_720w.jpg?source=1940ef5c)

我们可以看到Sigmoid的导数最大值为0.25，那么随着网络层数的增加，小于1的小数不断相乘导致 ![[公式]](https://www.zhihu.com/equation?tex=%E2%88%82y%2F%28%E2%88%82a_1+%29) 逐渐趋近于零，从而产生梯度消失。那么梯度爆炸又是怎么引起的呢？同样的道理，当权重初始化为一个较大值时，虽然和激活函数的导数相乘会减小这个值，但是随着神经网络的加深，梯度呈指数级增长，就会引发梯度爆炸。然而，从AlexNet开始，神经网络中就使用ReLU函数替换了Sigmoid，同时BN（Batch Normalization）层的加入，也基本解决了梯度消失或爆炸问题。

## 3、网络退化

现在，梯度消失或爆炸的问题已经解决了。这是不是就可以通过堆叠层数来加深网络了呢？Still no！

我们来看看ResNet论文中提到的例子（见图4），很明显，56层的深层网络，在训练集和测试集上的表现都远不如20层的浅层网络。这种随着网络层数加深，准确率（accuracy）逐渐饱和，然后出现急剧下降，具体表现为深层网络的训练效果反而不如浅层网络好的现象，被称为网络退化（degradation）。

![img](https://pic1.zhimg.com/50/v2-18e32492ed5a75e83b141b1ca02e4a46_720w.jpg?source=1940ef5c)

为什么会引起网络退化呢？按照理论上来说，当浅层网络效果不错的时候，网络层数的增加即使不会引起精度上的提升，也不该使模型效果变差。但事实上非线性的激活函数的存在，会造成很多不可逆的信息损失。网络加深到一定程度，过多的信息损失就会造成网络的退化。

而ResNet就是提出一种方法让网络拥有**恒等映射**能力，即随着网络层数的增加，深层网络至少不会差于浅层网络。

## 4、Residual Block

现在我们明白了，为了加深网络结构，使每一次能够学到更细化的特征从而提高网络精度，需要实现的一点是**恒等映射**。那么残差网络如何能够做到这一点呢？

恒等映射即为 ![[公式]](https://www.zhihu.com/equation?tex=H%28x%29%3Dx) ，已有的神经网络结构很难做到这一点。不过，如果我们将网络设计成 ![[公式]](https://www.zhihu.com/equation?tex=H%28x%29%3DF%28x%29%2Bx) ，即 ![[公式]](https://www.zhihu.com/equation?tex=F%28x%29%3DH%28x%29-+x) ，那么只需要使残差函数 ![[公式]](https://www.zhihu.com/equation?tex=F%28x%29%3D0) ，就构成了恒等映射 ![[公式]](https://www.zhihu.com/equation?tex=H%28x%29%3DF%28x%29) 。

![img](https://pic2.zhimg.com/80/v2-1e1321c87c4cc075349a748268705041_1440w.jpg?source=1940ef5c)

残差结构的目的是，随着网络的加深，因为网络拥有**恒等映射**的能力，所以网络可以试着使 ![[公式]](https://www.zhihu.com/equation?tex=F%28x%29) 逼近于0从而去更好地学习（拟合）训练数据而不是造成退化，从而让深度网络的精度在最优浅层网络的基础上不会下降。看到这里你或许会有疑问，既然如此为什么不直接选取最优的浅层网络呢？这是因为最优的浅层网络结构并不易找寻，而ResNet可以通过增加深度，找到最优的浅层网络并保证深层网络不会因为层数的叠加而发生网络退化。

# 优化算法

直接用最简单的梯度下降，每个训练样本都计算一次梯度，计算量太大，不实际。

如何提升优化效果：1.减少计算量   2.优化下降路径，用更少的步数，更快到达极值点。

## 随机梯度下降（SGD）

随机选取样本来代表总体，进行梯度计算（mini-batch）

假如极值点存在，随机梯度下降真的能收敛到那个极值点吗？

数学家证明了，在凸问题下：经过k次训练后，随机梯度下降法能到达的那个误差是根号k分之一。
$$
f(x^{k})-f^{*}=o(\frac{1}{\sqrt{k}})
$$
在强凸问题下，能达到k分之一的量级。
$$
f(x^{k})-f^{*}=o(\frac{1}{k})
$$
而标准梯度下降法收敛速度最快也不会超过k分之一，但它的计算量却很大，所以选用随机梯度下降是合理的。

## 牛顿法

动机：如何使优化路径更加贴近完美路径？

![微信截图_20210816105454](C:\Users\lzh\Videos\优化算法\微信截图_20210816105454.png)

![微信截图_20210816105714](C:\Users\lzh\Videos\优化算法\微信截图_20210816105714.png)

用二次曲线而不是直线去拟合。

![image-20210816105908995](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816105908995.png)

**牛顿法学习步长是确定的。**

上面的情况只有一维变量，高维情况下的牛顿法：

![image-20210816110258505](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816110258505.png)

但牛顿法有个很明显的缺点，就是计算量大，每次都需要计算一个Hessian矩阵并求逆。那有没有更好的优化思路呢？

## 动量法

牛顿法的本质就是把下降路径的所有的维度放在一起，统一考虑看看能不能找到一个更好的路径。那么我们现在试一试新的思路，把下降路径的一个维度、一个维度来考虑。

![image-20210816112348814](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816112348814.png)

![image-20210816112432880](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816112432880.png)

![image-20210816112447613](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816112447613.png)

![image-20210816112551121](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816112551121.png)

![image-20210816112636593](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816112636593.png)

![image-20210816114609134](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816114609134.png)

![image-20210816114640119](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816114640119.png)

![image-20210816114936368](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816114936368.png)

距离当前越远的数据影响越小，这种时序上的加权称为指数加权平均法

![image-20210816115147905](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816115147905.png)

以前的方向是有惯性的，要想它发生改变，必须把它们抵消，这就是动量法！

## Nesterov算法

其实对梯度下降法进行优化不只是可以考虑历史数据，还可以超前去参考未来的数据。

![image-20210816115919899](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816115919899.png)

如果它有一定预知能力，知道第二步要到那个点，那么第一步时的修正就不会那么小了，而是更大。

![image-20210816120047203](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816120047203.png)

![image-20210816120112959](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816120112959.png)

那么怎么做到超前呢？

这就是Nesterov算法

![image-20210816120205938](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816120205938.png)

先让点根据以往冲量修正后进行移动，再求梯度

![image-20210816120421062](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816120421062.png)

![image-20210816120438056](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816120438056.png)

假如这个红线是移动后求出的梯度方向，再拿进来去计算冲量Vt

![image-20210816120503559](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816120503559.png)

![image-20210816120633990](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816120633990.png)

## AdaGrad算法

我们发现，无论是动量法还是Nesterov法都是在训练和学习的过程中对那个参数的变化量，增加了一个0次项的修正。既然0次项（偏导的0次项）可以修正，那也可以对一次项（偏导的一次项）进行修正。也是说针对学习率也能进行一些修正呢？

![image-20210816121048909](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816121048909.png)

具体算法如下：
$$
W_{(t)i}=W_{(t-1)i}-\frac{\eta}{\sqrt{S(t)+\varepsilon}}\cdot\Delta W_{(t)i}
$$

$$
其中：S(t)=S(t-1)+\Delta W_{(t)i}\cdot \Delta W_{(t)i}
$$

$$
\Delta W_{(t)i}=\frac{\partial J(W_{(t-1)i})}{\partial W_i}
$$

如果这个维度历史数据修改得多，那么它对应的学习率就减少得多，分母的epsilon是修正，避免分母为零。

下图是动量法和AdaGrad法的对比：

![image-20210816123055613](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816123055613.png)

动量法修正的是偏导的0次项，而AdaGrad修正的是偏导的1次项，它们两个是不能互相替代的，这也为了后面这两种方法可以结合提供了可能性。

AdaGrad特别适合稀疏数据，在稀疏数据上效果特别好。

梯度上一个个的维度其实就是一个个的特征，如果这个特征对应的学习率比较大，那么在训练的时候对这个特征的调整就比较大。

稀疏数据集中，任意两个数据的不同主要体现在特征的不同上，而不是体现在某一个具体特征上的程度不一样。

稀疏数据就表示，它在某一个特征或者某一个维度上提供的数据就没有那么充分，那么这个时候做梯度下降法，可能比较容易出现震荡的情况。

举个例子

![image-20210816131741535](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816131741535.png) 

![image-20210816131808582](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816131808582.png)

随着维度的增加，球的体积是在变小的，甚至在维度趋于无穷大时，体积趋于零。

![image-20210816131922505](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816131922505.png)

A和B是同一纬度，但在这个维度上取值不同；而A和C，它们的维度压根不一样。而在计算体积的时候，更多的是依赖同一个维度上的取值不一样，因为这样才能有纵深。而当维度升的非常高的时候，一个球里两个点的不同，更多的是依赖维度的不一样，而不是某一个维度上的取值不一样，那这样纵深就没了，再去计算体积那就慢慢变小，直到没有。

然而，AdaGrad也有缺点：

![image-20210816132340956](C:\Users\lzh\AppData\Roaming\Typora\typora-user-images\image-20210816132340956.png)

本来应该快速下降的地方却走得很慢，因为它把所有的历史数据都考虑进来，我们可以使用指数加权平均法进行修正，这个方法叫做RMSprop。

## RMSprop

$$
S_{(t)}=\beta S_{(t-1)}+(1-\beta)\Delta W_{(t)i}\cdot \Delta W_{(t)i}
$$

$$
W_{(t)i}=W_{(t-1)i}-\frac{\eta}{\sqrt{S_{(t)}+\varepsilon}}\cdot \Delta W_{(t)i}
$$

## Adam

而把动量法结合进来，就是当今最为流行的Adam。（RMSprop+动量法引申出Adam）
$$
V(t)=\beta_{1}\cdot V_{(t-1)}+(1-\beta_{1})\cdot \Delta W_{(t)i}
$$

$$
S(t)=\beta_{2}S_{(t-1)}+(1-\beta_2)\Delta W_{(t)i}\cdot \Delta W_{(t)i}
$$

$$
W_{(t)i}=W_{(t-1)i}-\frac{\eta}{\sqrt{S_{(t)}}+\varepsilon}\cdot V_{(t)}
$$



总结起来就是对**方向以及步长进行优化**！